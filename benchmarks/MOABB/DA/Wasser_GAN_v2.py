import os
import torch

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Silences the warning and error logs generated by TensorFlow

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from keras.optimizers import Adam, RMSprop
from tensorflow import reduce_mean
from keras.models import Sequential
from keras.layers import Dense, Flatten, LeakyReLU, Dropout
from keras.layers import Reshape, BatchNormalization, Conv2D, Conv2DTranspose
from functools import partial


class WasserGAN_GP():




    def __init__(self,  epochs=100, sample_interval=10, channels=1, batchsize=32, task=1, subject=1):


        # Dataset features:
        self.epochs = epochs
        self.sample_interval = sample_interval
        self.channels = channels
        self.freq_sample = 256
        self.time_sample = 22
        self.eeg_shape = (self.freq_sample, self.time_sample, self.channels)

        # Model specific parameters (Noise generation, Dropout for overfitting reduction, etc...):
        self.noise = 100
        self.dropout = 0.25
        self.alpha = 0.2
        self.momentum = 0.8
        self.batchsize = batchsize
        self.critic_iter = 5
        self.gp_weight = 10

        # Choosing Adam optimiser for both generator and discriminator to feed in to the model:
        self.gen_optimiser = Adam(0.0002, 0.2) # Values from the EEG GAN paper found to be most optimal
        self.critic_optimiser = RMSprop(0.0005) # NOTE here we use a different optimiser for the critic
        # The RMSprop optimiser is more stable  than the Adam in terms of stability for the WGAN
        # This is from the Wasserstein GAN paper

        # Build both the Generator and Discriminator:
        # We will train the combined model this time, unlike standard GAN
        self.generator = self.make_generator()
        self.critic = self.make_critic()

        # Useful for creating a sample directory later
        self.dir = 'EEG_samples'
        self.subject = subject # Used to store the subject data later
        self.task = task # Used to store the task data later

    def make_generator(self):
        model = Sequential()

        # Calculate total size for the Dense layer to match the target shape (256, 22, 1)
        initial_dense_size = 64 * 16 * 11  # Choose a shape that can be upsampled to (256, 22)

        model.add(Dense(initial_dense_size, use_bias=False, input_shape=(self.noise,)))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(LeakyReLU())

        # Reshape to an intermediate shape (16, 11, 64)
        model.add(Reshape((16, 11, 64)))

        model.add(Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(LeakyReLU())

        model.add(Conv2DTranspose(32, (4, 4), strides=(2, 1), padding='same', use_bias=False))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(LeakyReLU())

        model.add(Conv2DTranspose(16, (4, 4), strides=(2, 1), padding='same', use_bias=False))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(LeakyReLU())

        model.add(Conv2DTranspose(1, (4, 4), strides=(2, 1), padding='same', use_bias=False, activation='tanh'))

        # Ensuring the output shape matches (256, 22)
        model.add(Reshape((256, 22)))


        assert model.output_shape == (None, 256, 22)

        return model

    def make_critic(self):
        model = Sequential()

        model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=(256, 22, self.channels)))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(Dropout(self.dropout))

        model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(Dropout(self.dropout))

        model.add(Flatten())
        model.add(Dense(1))

        assert model.output_shape == (None, 1)

        return model

    def make_fakedata(self, noise_shape=100):
        '''
        Generates the fake data by drawing random samples from
        a normal Gaussian distribution (which is what np.random.normal
        does). This is for the generator to use.
        :return: Generated signal, Noise np.array
        '''
        noise = np.random.normal(0, 1, (noise_shape, self.noise))
        return self.generator(noise, training=False), noise


    def critic_loss(self, f_logits, r_logits):
        '''
        Implementation of the critic and generator loss using the Wasserstein
        Loss Function. For the critic, it uses the average critic score 'tf-
        reduce_mean' of the fake signals (or logits, probability values using
        logistic regression) minus the average critic score of real signals. This
        is done in order to maximise the gap between scores of real and fake signals.
        :param f_logits: fake signal probability scores
        :param r_logits: real signal proability scores
        :return: Wasserstein Critic Loss Value
        '''
        return reduce_mean(f_logits) - reduce_mean(r_logits)

    def generator_loss(self, f_logits):
        '''
        Like critic loss, except the generator loss uses only the average critic score
        of fake signals rather than both for its update. An added benefit of the WGAN
        is that it learns whether the generator is performing or not.
        :param fake_logits: fake signal probability scores
        :return: Wasserstein Generator Loss Value
        '''
        return - reduce_mean(f_logits)

    def gradient_penalty(self, critic, real_signal, fake_signal):
        '''
        Gradient penalty is used instead of weight clipping to enforce the
        Lipschitz Constraint 'LC' (uniform continuitiy between loss functions).
        It also helps reduce exploding gradients. The GP term penalizes the
        model if the gradient norm moves away from 1 (This means that the
        functions are not 1-Lipschitz where gradient norms are different values.)
        :param discriminator:
        :param real_signal:
        :param fake_signal:
        :return: Gradient Penalty term added to critic loss
        '''

        # Draw samples from a uniform distribution
        delta = tf.random.uniform([real_signal.shape[0], 1, 1], 0., 1.)
        inter = real_signal + (delta * (real_signal - fake_signal))

        # Use GradientTape to watch the gradient variables.
        with tf.GradientTape() as tape:
            tape.watch(inter)
            pred = critic(inter)

        # Uses the squared difference from 1 norm as the Gradient Penalty
        grad = tape.gradient(pred, inter)
        gradient_l2_norm = tf.sqrt(tf.reduce_sum(tf.square(grad)))

        return reduce_mean(gradient_l2_norm)

    @tf.function
    def train_step(self, sig):
        '''
        Similar to train_step in DCGAN however, recall that for the WGAN we
        train the critic over several iterations to improve stability,
        hence the term critic_iter. Also uses GradientTape() to watch over
        the trainable weights etc...
        :param sig: takes in the real signal
        :return: generator and discriminator loss
        '''



        for _ in range(self.critic_iter):
            with tf.GradientTape() as disc_tape:
                noise = tf.random.normal([sig.shape[0], self.noise])

                gen_sig = self.generator(noise, training=True)
                gen_sig = tf.reshape(gen_sig, sig.shape)
                f_logits = self.critic(gen_sig, training=True)
                r_logits = self.critic(sig, training=True)

                critic_loss = self.critic_loss(f_logits, r_logits)
                gp = self.gradient_penalty(partial(self.critic, training=True), sig, gen_sig)
                critic_loss += self.gp_weight * gp

            disc_grads = disc_tape.gradient(critic_loss, self.critic.trainable_variables)
            self.critic_optimiser.apply_gradients(zip(disc_grads, self.critic.trainable_variables))

        noise = tf.random.normal([sig.shape[0], self.noise])

        with tf.GradientTape() as gen_tape:
            gen_sig = self.generator(noise, training=True)
            gen_sig = tf.reshape(gen_sig, sig.shape)
            f_logits = self.critic(gen_sig, training=True)
            gen_loss = self.generator_loss(f_logits)

        gen_grads = gen_tape.gradient(gen_loss, self.generator.trainable_variables)
        self.gen_optimiser.apply_gradients(zip(gen_grads, self.generator.trainable_variables))

        return critic_loss, gen_loss

    # training loop
    def forward(self, waveforms, loss_threshold=10000, start_appending_epoch=1):
        '''
        The training function that has a loop which trains the model on
        every epoch/iteration. Calls the train_step() compiled function
        which trains the combined model at the same time.
        '''

        gen_loss, disc_loss = [], []
        g_tot, d_tot = [], []

        # If waveforms is a numpy array, convert to float32 and create a TensorFlow waveforms
        if isinstance(waveforms, np.ndarray):
            waveforms = waveforms.astype('float32')
            data = tf.data.Dataset.from_tensor_slices(waveforms).shuffle(buffer_size=waveforms.shape[0]).batch(self.batchsize)
        elif isinstance(waveforms, tf.Tensor):
            data = tf.data.Dataset.from_tensor_slices(waveforms).shuffle(buffer_size=waveforms.shape[0]).batch(self.batchsize)
        else:
            raise TypeError("Dataset must be a numpy array or a TensorFlowÂ tensor")



        # start training loop
        for epoch in range(self.epochs):

            for image_batch in data:
                disc_loss_batch, gen_loss_batch = self.train_step(image_batch)

                # Turn into Numpy Array
                disc_loss_batch = tf.reduce_mean(disc_loss_batch).numpy() / float(self.critic_iter)
                gen_loss_batch = tf.reduce_mean(gen_loss_batch).numpy()

                gen_loss.append(gen_loss_batch)
                disc_loss.append(disc_loss_batch)

            g_loss = sum(gen_loss) / len(gen_loss)
            d_loss = sum(disc_loss) / len(disc_loss)

            g_tot.append(g_loss)
            d_tot.append(d_loss)

            # if epoch >= start_appending_epoch and g_loss < loss_threshold and d_loss < loss_threshold:
            #     noise = tf.random.normal([waveforms.shape[0], self.noise])
            #     #print(noise.shape)
            #     generated_data = self.generator(noise, training=False).numpy()
            #     print(generated_data.shape)
            #     waveforms = np.concatenate((waveforms, generated_data), axis=0)

            if epoch % self.sample_interval == 0:
                # print("epoch: {}, generator loss: {}, discriminator loss: {}".format
                #       (epoch, g_loss, d_loss))

                # Allows us to generate the signal and get the fake one for a
                # Arbitrary trial number. Plots it and save it every sample_interval
                # Which is 100 in this case.
                generated_signal, _ = self.make_fakedata(noise_shape=100)
                trial_num = 0
                real_signal = np.expand_dims(waveforms[trial_num], axis=0)

                # Plots the generated samples for the selected channels.
                # Recall the channels are chosen during the Load_and_Preprocess Script
                # Here they just correspond to C3 only (channel 7 was selected).
                # fig, axs = plt.subplots(1, 2)
                # fig.suptitle('Comparison of Generated vs. Real Signal (Spectrogram) for one trial, one channel')
                # fig.tight_layout()
                # axs[0].imshow(generated_signal[0, :, :], aspect='auto')
                # axs[0].set_title('Generated Signal', size=10)
                # axs[0].set_xlabel('Time Sample')
                # axs[0].set_ylabel('Frequency Sample')
                # axs[1].imshow(real_signal[0, :, :], aspect='auto')
                # axs[1].set_title('Fake Signal', size=10)
                # axs[1].set_xlabel('Time Sample')
                # axs[1].set_ylabel('Frequency Sample')
                # plt.show()

                # Save the generated samples within the current working dir
                # in a folder called 'EEG Samples', every 100 epochs.
                #if not os.path.exists(self.dir):
                #    os.makedirs(self.dir)

                #plt.savefig("%s/%d.png" % (self.dir, epoch))
                #plt.close()

        #qual a policy para adicionar um generated signal ao dataset com as waveforms?
        #ver a qualidade e se passar de x entao adicioanar?
        #a partir de x epochs comecar a adicionar?
        #se generator loss for menor que um certo valor comecar a adiocnar?



        # Plot the generator and discriminator losses for all the epochs
        # plt.figure()
        # plt.plot(g_tot, 'r')
        # plt.plot(d_tot, 'b')
        # plt.title('Loss history')
        # plt.xlabel('Epochs')
        # plt.ylabel('Loss')
        # plt.legend(['Generator', 'Discriminator'])
        # plt.grid()
        # plt.show()

        # Save subject and task data such that it can be used to generate
        # Fake samples later
        #fp = os.path.join(os.getcwd(), 'EEG_Samples')
        #sp = os.path.join(fp, 'Subject{}WGAN_Model_Data_For_Task{}.h5'.format(self.subject, self.task))
        #self.generator.save(sp)

        noise = tf.random.normal([waveforms.shape[0], self.noise])
        generated_data = self.generator(noise, training=False).numpy()
      
        return generated_data



# train_data = torch.ones((4, 256, 22)) * torch.arange(4).reshape((4, 1, 1,))
# train_data = train_data.numpy()


# # Instantiate Object
# x = WasserGAN_GP()
# augmented_data = x.forward(train_data)

# print(train_data.shape)
# print(augmented_data.shape)


