import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from keras.optimizers import Adam
from keras.losses import BinaryCrossentropy
from keras.models import Sequential
from keras.layers import Dense, Flatten, LeakyReLU, Dropout, Input
from keras.layers import Reshape, BatchNormalization, Conv2D, Conv2DTranspose

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Silences the warning and error logs generated by TensorFlow

class DCGAN:
    def __init__(self, epochs=100, sample_interval=10, channels=1, batchsize=2):
        self.epochs = epochs
        self.sample_interval = sample_interval
        self.channels = channels
        self.freq_sample = 256
        self.time_sample = 22
        self.eeg_shape = (self.freq_sample, self.time_sample, self.channels)
        self.noise = 100
        self.dropout = 0.25
        self.alpha = 0.2
        self.momentum = 0.8
        self.batchsize = batchsize

        # Choosing Adam optimizer for both generator and discriminator
        self.optimiser_gen = Adam(0.0002, 0.5)
        self.optimiser_disc = Adam(0.0002, 0.5)

        # Build both the Generator and Discriminator
        self.generator = self.make_generator()
        self.discriminator = self.make_discriminator()

        self.dir = 'EEG_samples'

    def make_generator(self):
        model = Sequential()

        initial_dense_size = 64 * 16 * 11

        model.add(Input(shape=(self.noise,)))
        model.add(Dense(initial_dense_size, use_bias=False))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(LeakyReLU())

        model.add(Reshape((16, 11, 64)))

        model.add(Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(LeakyReLU())

        model.add(Conv2DTranspose(32, (4, 4), strides=(2, 1), padding='same', use_bias=False))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(LeakyReLU())

        model.add(Conv2DTranspose(16, (4, 4), strides=(2, 1), padding='same', use_bias=False))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(LeakyReLU())

        model.add(Conv2DTranspose(1, (4, 4), strides=(2, 1), padding='same', use_bias=False, activation='tanh'))
        model.add(Reshape((256, 22)))

        assert model.output_shape == (None, 256, 22)

        return model

    def make_discriminator(self):
        model = Sequential()

        model.add(Input(shape=(256, 22, self.channels)))
        model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same'))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(Dropout(self.dropout))

        model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(Dropout(self.dropout))

        model.add(Flatten())
        model.add(Dense(1))

        assert model.output_shape == (None, 1)

        return model

    def make_fakedata(self, noise_shape=100):
        noise = np.random.normal(0, 1, (noise_shape, self.noise))
        gen_imgs = self.generator.predict(noise)
        return gen_imgs, noise

    def discriminator_loss(self, real_output, fake_output):
        cross_entropy = BinaryCrossentropy(from_logits=True)
        real_loss = cross_entropy(tf.ones_like(real_output), real_output)
        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
        total_loss = real_loss + fake_loss
        return total_loss

    def generator_loss(self, fake_output):
        cross_entropy = BinaryCrossentropy(from_logits=True)
        return cross_entropy(tf.ones_like(fake_output), fake_output)

    @tf.function
    def train_step(self, images):
        noise = tf.random.normal([self.batchsize, self.noise])
        
        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
            generated_images = self.generator(noise, training=True)

            real_output = self.discriminator(images, training=True)
            fake_output = self.discriminator(generated_images, training=True)

            gen_loss = self.generator_loss(fake_output)
            disc_loss = self.discriminator_loss(real_output, fake_output)

        grad_gen = gen_tape.gradient(gen_loss, self.generator.trainable_variables)
        grad_disc = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)

        self.optimiser_gen.apply_gradients(zip(grad_gen, self.generator.trainable_variables))
        self.optimiser_disc.apply_gradients(zip(grad_disc, self.discriminator.trainable_variables))

        return disc_loss, gen_loss

    def forward(self, waveforms, loss_threshold=0.1, start_appending_epoch=50):
        if isinstance(waveforms, np.ndarray):
            waveforms = waveforms.astype('float32')
            #waveforms = np.expand_dims(waveforms, axis=-1)  # Adding channel dimension
            data = tf.data.Dataset.from_tensor_slices(waveforms).shuffle(buffer_size=waveforms.shape[0]).batch(self.batchsize)
        elif isinstance(waveforms, tf.Tensor):
            #waveforms = tf.expand_dims(waveforms, axis=-1)  # Adding channel dimension
            data = tf.data.Dataset.from_tensor_slices(waveforms).shuffle(buffer_size=waveforms.shape[0]).batch(self.batchsize)
        else:
            raise TypeError("Dataset must be a numpy array or a TensorFlow tensor")

        gen_loss, disc_loss = [], []
        g_tot, d_tot = [], []

        for epoch in range(self.epochs):
            for image_batch in data:
                disc_loss_batch, gen_loss_batch = self.train_step(image_batch)
                gen_loss.append(gen_loss_batch)
                disc_loss.append(disc_loss_batch)

            g_loss = sum(gen_loss) / len(gen_loss)
            d_loss = sum(disc_loss) / len(disc_loss)

            g_tot.append(g_loss)
            d_tot.append(d_loss)

            if epoch % self.sample_interval == 0:
                #print(f"Epoch {epoch}, Generator loss: {g_loss.numpy()}, Discriminator loss: {d_loss.numpy()}")

                # Allows us to generate the signal and get the fake one for a
                # Arbitrary trial number. Plots it and save it every sample_interval
                # Which is 100 in this case.
                generated_signal, _ = self.make_fakedata(noise_shape=100)
                trial_num = 0
                real_signal = np.expand_dims(waveforms[trial_num], axis=0)

                # Plots the generated samples for the selected channels.
                # Recall the channels are chosen during the Load_and_Preprocess Script
                # Here they just correspond to C3 only (channel 7 was selected).
                # fig, axs = plt.subplots(1, 2)
                # fig.suptitle('Comparison of Generated vs. Real Signal (Spectrogram) for one trial, one channel')
                # fig.tight_layout()
                # axs[0].imshow(generated_signal[0, :, :], aspect='auto')
                # axs[0].set_title('Generated Signal', size=10)
                # axs[0].set_xlabel('Time Sample')
                # axs[0].set_ylabel('Frequency Sample')
                # axs[1].imshow(real_signal[0, :, :], aspect='auto')
                # axs[1].set_title('Fake Signal', size=10)
                # axs[1].set_xlabel('Time Sample')
                # axs[1].set_ylabel('Frequency Sample')
                # plt.show()

                # Save the generated samples within the current working dir
                # in a folder called 'EEG Samples', every 100 epochs.
                #if not os.path.exists(self.dir):
                #    os.makedirs(self.dir)

                #plt.savefig("%s/%d.png" % (self.dir, epoch))
                #plt.close()

            # if epoch >= start_appending_epoch and g_loss.numpy() < loss_threshold and d_loss.numpy() < loss_threshold:
            #     noise = tf.random.normal([waveforms.shape[0], self.noise])
            #     generated_data = self.generator(noise, training=False).numpy()
            #     waveforms = np.concatenate((waveforms, generated_data), axis=0)

            # Clear loss lists for the next epoch
            gen_loss.clear()
            disc_loss.clear()


        # # Plot the generator and discriminator losses for all the epochs
        # plt.figure()
        # plt.plot(g_tot, 'r')
        # plt.plot(d_tot, 'b')
        # plt.title('Loss history')
        # plt.xlabel('Epochs')
        # plt.ylabel('Loss')
        # plt.legend(['Generator', 'Discriminator'])
        # plt.grid()
        # plt.show()

        noise = tf.random.normal([waveforms.shape[0], self.noise])
        generated_data = self.generator(noise, training=False).numpy()
        #print(generated_data.shape)
        #print(waveforms.shape)
        waveforms = np.concatenate((waveforms, generated_data), axis=0)
        return generated_data



# Example usage
train_data = np.ones((4, 256, 22)) * np.arange(4).reshape((4, 1, 1))
train_data = train_data.astype(np.float32)

dcgan = DCGAN()
augmented_data = dcgan.forward(train_data)

print(train_data.shape)
print(augmented_data.shape)



