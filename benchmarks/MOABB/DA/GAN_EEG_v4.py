import numpy as np
import os
import torch
import tensorflow as tf
import torch.nn as nn

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Silences the warning and error logs generated by TensorFlow

import matplotlib.pyplot as plt
from keras.optimizers import Adam
from keras.models import Sequential, Model
from keras.layers import Input, Dense, Flatten, LeakyReLU, Reshape, BatchNormalization

class GAN_EEG_v4(nn.Module):
	def __init__(self, epochs=10, batchsize=2, sample_interval=10, channels=1, noise=100, dropout=0.2, alpha=0.2, momentum=0.8, adam_learning_rate=0.0002, adam_beta_1=0.2):
		super(GAN_EEG_v4, self).__init__()
		#Dataset features
		self.epochs = epochs
		self.batchsize = batchsize
		self.sample_interval = sample_interval
		self.channels = channels
		self.time_stamp = 256 
		self.eeg_shape = (self.time_stamp, self.channels)

		#Model specific parameters (Noise generation, Dropout for overfitting reduction, etc...):
		self.noise = noise
		self.dropout = dropout
		self.alpha = alpha
		self.momentum = momentum

		#Choosing Adam optimizer for both generator and discriminator to feed in to the model:
		self.optimizer = Adam(adam_learning_rate, adam_beta_1) # Values from the EEG GAN paper found to be most optimal

		#Builds the Generator, Discriminator and the combined models:
		self.generator = self.make_generator()

		self.discriminator = self.make_discriminator()
		self.discriminator.compile(loss='binary_crossentropy', optimizer=self.optimizer, metrics=['accuracy'])

		self.combined = self.builder()
		self.combined.compile(loss='binary_crossentropy', optimizer=self.optimizer)

		#Useful for creating a sample directory later
		self.dir = 'EEG_samples'

	def forward(self, waveforms):
		print("SHAPE")
		print(waveforms.shape)
		return self.train(waveforms)

	def make_generator(self):
		'''
		Creates a generator model that takes in randomly generated noise, then uses 
		3 Dense layers to return an image that is fed into the discriminator, 
		Which then distinguishes wether or not it is a real or fake one. Weights are adjusted 
		accordingly such that it can eventually generate a real signal. 
		:return: Model date tuple(generated noise, eeg img)
		'''
		model = Sequential()

		model.add(Dense(256, input_dim=self.noise))
		model.add(LeakyReLU(alpha=self.alpha))
		model.add(BatchNormalization(momentum=self.momentum))
		model.add(Dense(512))
		model.add(LeakyReLU(alpha=self.alpha))
		model.add(Dense(1024))
		model.add(LeakyReLU(alpha=self.alpha))
		model.add(BatchNormalization(momentum=self.momentum))
		model.add(Dense(np.prod(self.eeg_shape), activation='tanh'))
		model.add(Reshape(self.eeg_shape))
		assert model.output_shape == (None, 256, self.channels) # was 1793 originally but changed to 256 to match timestamp

		noise = Input(shape=(self.noise,))
		img = model(noise)

		return Model(noise, img)

	def make_discriminator(self):
		'''
		Creates a discriminator model that distinguishes the fed images from generator,
		and also is trained using a training loop (see below). The Discriminator is a simple 
		2 Dense layer Neural Network that return either a 'True' or 'False'. Values are then 
		adjusted accordingly per each epoch to update weights and biases such that it produces
		the right output (i.e. it can discriminate fake from real).
		:return: Model data tuple (image from generator, validity [true or false])
		'''
		model = Sequential()

		model.add(Flatten(input_shape=self.eeg_shape))
		model.add(Dense(512))
		model.add(LeakyReLU(alpha=self.alpha))
		model.add(Dense(256))
		model.add(LeakyReLU(alpha=self.alpha))
		model.add(Dense(1, activation='sigmoid'))

		img = Input(shape=self.eeg_shape)
		validity = model(img)

		return Model(img, validity)

	def builder(self):
		'''
		Function that allows us to build the combined generator + discriminator model.
		In return, this lets the generator eventually fool the discriminator (Where 
		the discriminator takes in the generated signal and determines whether
		it's real or fake).

		NOTE the discriminator.trainable = False, meaning that only the generator is trained 
		here, while the discriminator is not trainable for the COMBINED model. This step takes
		place before model compilation.

		:return: Model data tuple(noise signal 'z', validity[True/False])
		'''

		z = Input(shape=(self.noise,))
		generated_eeg = self.generator(z)

		discriminator = self.discriminator
		discriminator.trainable = False

		validity = discriminator(generated_eeg)

		return Model(z, validity)

	def train(self, dataset, loss_threshold=10000, start_appending_epoch=1):
		'''
		Training function used to allow us to pass all the training data per epoch to both the
		generator and discriminator. Notice how the discriminator is still trained per batch 
		but not for the combined model.
		:param dataset: input/training dataset from load_preprocess
		:param epochs: number of epochs (1 epoch = 1 pass of all the training data) the models loop through
		:param batchsize: number of batches.
		:param sample_interval: at what interval do we present and save the results (see below)
		:return: None
		'''

		valid = np.ones((self.batchsize, 1))
		fake = np.zeros((self.batchsize, 1))

		gen_loss = []
		disc_loss = []

		for epoch in range(self.epochs):

			#Discriminator Training Loop
			idx = np.random.randint(0, dataset.shape[0], self.batchsize)
			signal = dataset[idx]

			noise = np.random.normal(0, 1, (self.batchsize, self.noise))

			gen_signals = self.generator.predict(noise)

			d_loss_real = self.discriminator.train_on_batch(signal, valid)
			d_loss_fake = self.discriminator.train_on_batch(gen_signals, fake)
			d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

			#Generator Training Loop
			noise = np.random.normal(0, 1, (self.batchsize, self.noise))

			#Combined model training where generator is trained to fool the discriminator
			g_loss = self.combined.train_on_batch(noise, valid)

			gen_loss.append(g_loss)
			disc_loss.append(d_loss[0])

			#print("EPOCH %d" % (epoch))
			#print(g_loss)
			#print(d_loss)


			# if epoch >= start_appending_epoch and g_loss[0] < loss_threshold and d_loss[0] < loss_threshold:
			# 	noise = tf.random.normal([dataset.shape[0], self.noise])
			# 	#print(noise.shape)
			# 	generated_data = self.generator(noise, training=False).numpy()
			# 	#print(generated_data.shape)
			# 	dataset = np.concatenate((dataset, generated_data), axis=0)

			#Prints the Discriminator and Generator loss alongside accuracy
			#Per sample interval
			#if epoch % self.sample_interval == 0:
				#print("%d [Discriminator loss: %f, Accuracy: %.2f%%] [Generator loss %f]" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))
				#self.sample_eeg(epoch)

		# plt.plot(gen_loss, 'r')
		# plt.plot(disc_loss, 'b')
		# plt.title('Discriminator & Generator Loss per Epoch')
		# plt.xlabel('Epochs')
		# plt.ylabel('Loss')
		# plt.legend(['Generator Loss', 'Discriminator Loss'])
		# plt.grid()
		# plt.show()

		noise = tf.random.normal([dataset.shape[0], self.noise])
		generated_data = self.generator(noise, training=False).numpy()
		return generated_data

	def sample_eeg(self, epoch):
		'''
		Allows us to retrieve the generated sample from the generator
		then plot it. See below comments for step by step procedure.
		:param epoch: Epoch number
		:return: None
		'''

		num_signals = 249
		noise = np.random.normal(0, 1, (num_signals, self.noise))
		gen_signal = self.generator.predict(noise)

		#Normalize
		gen_signal = 0.5 * gen_signal + 0.5

		#Plots the generated samples for the selected channels.
		# Recall the channels are chosen during the Load_and_Preprocess Script
		# Here they correspond to FZ, C3, Cz, C4 and Pz respectively.
		fig, axs = plt.subplots(5, sharex=True)
		fig.suptitle('Artifical EEG Data images per channel')
		fig.tight_layout()
		axs[0].imshow(gen_signal[:, :, 0])
		axs[0].set_title('Fz', size=10)
		axs[0].imshow(gen_signal[:, :, 1])
		axs[0].set_title('C3', size=10)
		axs[0].imshow(gen_signal[:, :, 2])
		axs[0].set_title('Cz', size=10)
		axs[0].imshow(gen_signal[:, :, 3])
		axs[0].set_title('C4', size=10)
		axs[0].imshow(gen_signal[:, :, 4])
		axs[0].set_title('Pz', size=10)

		#Save the generated samples within the current working dir
		# in a folder called 'EEG Samples', every 100 epochs.
		if not os.path.exists(self.dir):
			os.makedirs(self.dir)

		plt.savefig("%s/%d.png" % (self.dir, epoch))
		plt.close()

		return None

	




# #Example usage:
# gan = GAN_EEG_v4(channels=22)

# #Use the provided signal
# signal = torch.ones((4, 256, 22)) * torch.arange(4).reshape((4, 1, 1,))

# augmented_data = gan.forward(signal)

# print(signal.shape)
# print(augmented_data.shape)
